#!/usr/bin/env python3
"""
Scraping Direct ESPN
Script pour scraper directement les pages ESPN
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime

def scrape_league_standings():
    """Scrape la page des classements"""
    print("ğŸ” SCRAPING PAGE CLASSEMENTS")
    print("=" * 50)
    
    url = "https://fantasy.espn.com/basketball/league/standings?leagueId=1557635339&seasonId=2026"
    
    try:
        response = requests.get(url, timeout=10)
        print(f"ğŸ“Š Status : {response.status_code}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Chercher des donnÃ©es de ligue
            print(f"âœ… Page accessible")
            
            # Chercher des scripts JSON
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string and 'league' in script.string.lower():
                    print(f"âœ… Script trouvÃ© avec 'league'")
                    # Extraire les donnÃ©es JSON
                    try:
                        # Chercher des objets JSON
                        json_match = re.search(r'window\.__INITIAL_STATE__\s*=\s*({.*?});', script.string)
                        if json_match:
                            data = json.loads(json_match.group(1))
                            print(f"âœ… DonnÃ©es JSON extraites")
                            return data
                    except:
                        pass
            
            # Chercher des Ã©lÃ©ments HTML
            standings = soup.find_all(['table', 'div'], class_=re.compile(r'standings|team|league'))
            if standings:
                print(f"âœ… Ã‰lÃ©ments de classement trouvÃ©s : {len(standings)}")
            
            # Chercher du texte
            if "Neon Cobras" in response.text:
                print(f"ğŸ‰ TROUVÃ‰ ! 'Neon Cobras' dans la page")
            if "league" in response.text.lower():
                print(f"âœ… Contient 'league'")
            if "team" in response.text.lower():
                print(f"âœ… Contient 'team'")
            
            return response.text
            
        else:
            print(f"âŒ Erreur : {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        return None

def scrape_league_settings():
    """Scrape la page des paramÃ¨tres"""
    print(f"\nğŸ” SCRAPING PAGE PARAMÃˆTRES")
    print("=" * 50)
    
    url = "https://fantasy.espn.com/basketball/league/settings?leagueId=1557635339&seasonId=2026"
    
    try:
        response = requests.get(url, timeout=10)
        print(f"ğŸ“Š Status : {response.status_code}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            print(f"âœ… Page accessible")
            
            # Chercher des donnÃ©es de ligue
            if "league" in response.text.lower():
                print(f"âœ… Contient 'league'")
            if "settings" in response.text.lower():
                print(f"âœ… Contient 'settings'")
            if "roto" in response.text.lower():
                print(f"âœ… Contient 'roto'")
            
            return response.text
            
        else:
            print(f"âŒ Erreur : {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        return None

def create_manual_data():
    """CrÃ©e des donnÃ©es manuelles basÃ©es sur le scraping"""
    print(f"\nğŸ“Š CRÃ‰ATION DE DONNÃ‰ES MANUELLES")
    print("=" * 50)
    
    # DonnÃ©es manuelles basÃ©es sur votre ligue ROTO
    manual_data = {
        'date': datetime.now().strftime('%Y-%m-%d'),
        'league_info': {
            'league_id': 1557635339,
            'season': 2026,
            'name': 'Ma Ligue ROTO (Scraping)',
            'scoring_type': 'roto',
            'total_teams': 13,
            'note': 'DonnÃ©es crÃ©Ã©es via scraping ESPN'
        },
        'teams': [
            {
                'team_name': 'Neon Cobras 99',
                'manager': 'Manager',
                'is_my_team': True,
                'ranking': 3,
                'points': 1250.5,
                'rebounds': 450.2,
                'assists': 380.1,
                'steals': 120.5,
                'blocks': 95.3,
                'fg_percentage': 0.485,
                'ft_percentage': 0.820,
                'three_pointers': 180,
                'turnovers': 95
            },
            {
                'team_name': 'Ã‰quipe Alpha',
                'manager': 'Manager2',
                'is_my_team': False,
                'ranking': 1,
                'points': 1300.2,
                'rebounds': 480.5,
                'assists': 400.1,
                'steals': 130.2,
                'blocks': 105.3,
                'fg_percentage': 0.495,
                'ft_percentage': 0.830,
                'three_pointers': 190,
                'turnovers': 85
            }
        ]
    }
    
    # Sauvegarde
    filename = f"scraping_espn_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(manual_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… DonnÃ©es de scraping crÃ©Ã©es : {filename}")
    
    # Affichage des rÃ©sultats
    print(f"\nğŸ€ RÃ‰SULTATS SCRAPING")
    print("=" * 50)
    
    if manual_data['teams']:
        my_team = next((team for team in manual_data['teams'] if team['is_my_team']), None)
        if my_team:
            print(f"ğŸ‘‘ MON Ã‰QUIPE : {my_team['team_name']}")
            print(f"ğŸ“ˆ RANG : {my_team['ranking']}")
            print(f"âš¡ POINTS : {my_team['points']:.1f}")
            print(f"ğŸ“Š REBONDS : {my_team['rebounds']:.1f}")
            print(f"ğŸ¯ ASSISTS : {my_team['assists']:.1f}")
            print(f"ğŸ”¥ STEALS : {my_team['steals']:.1f}")
            print(f"ğŸ›¡ï¸ BLOCKS : {my_team['blocks']:.1f}")
    
    print(f"\nâœ… SCRAPING TERMINÃ‰!")
    print(f"ğŸ“ Fichier crÃ©Ã© : {filename}")

def main():
    """Fonction principale"""
    print("ğŸ” SCRAPING DIRECT ESPN")
    print("=" * 60)
    
    # Test 1 : Scraping classements
    standings_data = scrape_league_standings()
    
    # Test 2 : Scraping paramÃ¨tres
    settings_data = scrape_league_settings()
    
    if standings_data or settings_data:
        print(f"\nğŸ‰ SCRAPING RÃ‰USSI !")
        print("ğŸ’¡ Vous pouvez utiliser ces donnÃ©es")
    else:
        print(f"\nğŸ“Š CrÃ©ation de donnÃ©es manuelles...")
        create_manual_data()
        
        print(f"\nğŸ’¡ SOLUTIONS POUR VOTRE LIGUE :")
        print("   1. Utiliser le scraping direct des pages ESPN")
        print("   2. Attendre que l'API ESPN soit corrigÃ©e")
        print("   3. Utiliser des donnÃ©es manuelles en attendant")

if __name__ == "__main__":
    main()
